{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ToposTextThucycides.html') as ifh:\n",
    "    html = ''.join(ifh.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(html[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_list = soup.findAll(\"p\")\n",
    "\n",
    "# for x in p_list[1:6]:\n",
    "#     print(x, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "book_line_pat = re.compile('(?P<book>[0-9]+)\\.(?P<line>[0-9]+)')\n",
    "id_from_link_pat = re.compile('place/(?P<id>.+)$')\n",
    "\n",
    "\n",
    "names = []\n",
    "longs = []\n",
    "lats = []\n",
    "links = []\n",
    "books = []\n",
    "lines = []\n",
    "ids = []\n",
    "\n",
    "\n",
    "for p in p_list:\n",
    "    places = p.findAll(\"a\", class_ = \"place\")\n",
    "    if places != []:\n",
    "        string_with_book_and_line = p.b.text\n",
    "        book = book_line_pat.search(string_with_book_and_line).group('book')\n",
    "        line = book_line_pat.search(string_with_book_and_line).group('line')\n",
    "#         print(string_with_book_and_line)\n",
    "        for place in places:\n",
    "            name = place.text\n",
    "            long = place.get(\"long\")\n",
    "            lat = place.get(\"lat\")\n",
    "            link = place.get(\"about\")\n",
    "            placeID = id_from_link_pat.search(link).group('id')\n",
    "            names.append(name)\n",
    "            longs.append(long)\n",
    "            lats.append(lat)\n",
    "            links.append(link)\n",
    "            ids.append(placeID)\n",
    "            books.append(book)\n",
    "            lines.append(line)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "place_df = pd.DataFrame({'name': names, 'placeID': ids, 'longitude': longs, \"latitude\": lats, \"link\": links, \"book\": books, \"line\": lines})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "link_counts = {}\n",
    "for link in place_df['link']:\n",
    "    if link in link_counts:\n",
    "        link_counts[link] += 1\n",
    "    else:\n",
    "        link_counts[link] = 1\n",
    "\n",
    "# print(place_df.head(10))\n",
    "\n",
    "# for k in link_counts:\n",
    "#     print(k, link_counts[k])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(len(place_df)):\n",
    "#     print(place_df['name'], i)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "link_list = place_df['link'].tolist()\n",
    "for i in range(len(place_df)):\n",
    "#     print(place_df['name'], i)\n",
    "    counts.append(link_counts[link_list[i]])\n",
    "#     print(place_df['link'], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_df['count'] = counts\n",
    "\n",
    "# print(place_df.head(10))\n",
    "\n",
    "\n",
    "# for k in link_counts:\n",
    "#     print(k, link_counts[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the request for the geojson:\n",
    "\n",
    "params = {\n",
    "    'work_id': 2\n",
    "}\n",
    "r = requests.get('https://topostext.org/api/place/geojsonwork.php', params=params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoj = r.text\n",
    "\n",
    "# print(geoj)\n",
    "# pp.pprint(geoj)\n",
    "\n",
    "with open('geoj.json', \"w\") as gjfh:\n",
    "    gjfh.writelines(geoj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JSON as dictionary\n",
    "geoj_dict=json.loads(geoj)\n",
    "\n",
    "\n",
    "# print(geoj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_dict_list = geoj_dict['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeID_dict = {}\n",
    "\n",
    "for place in places_dict_list:\n",
    "    id = place['properties']['placeID']\n",
    "    if place['properties']['featureTypes'] == 'sanctuary/temple':\n",
    "        featureTypes = 'temple'\n",
    "    else:\n",
    "        featureTypes = place['properties']['featureTypes']\n",
    "    description = place['properties']['description']\n",
    "    greek = place['properties']['greek2']\n",
    "    placeID_dict[id] = {'featureTypes': featureTypes, 'description': description, 'greek': greek}\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# pp.pprint(placeID_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureTypes = []\n",
    "descriptions = []\n",
    "id_list = place_df['placeID'].tolist()\n",
    "\n",
    "for i in range(len(place_df)):\n",
    "#     print(i, placeID_dict[id_list[i]])\n",
    "    try:\n",
    "        featureTypes.append(placeID_dict[id_list[i]]['featureTypes'])\n",
    "        descriptions.append(placeID_dict[id_list[i]]['description'])\n",
    "    except KeyError:\n",
    "        featureTypes.append('?')\n",
    "        descriptions.append('?')\n",
    "\n",
    "# print(id_list[64])\n",
    "# print(id_list[65]) #problem!\n",
    "# print(id_list[66])\n",
    "\n",
    "# print(placeID_dict[id_list[64]])\n",
    "# print(placeID_dict[id_list[64]]['featureTypes'])\n",
    "# print(placeID_dict[id_list[65]]) #problem!\n",
    "# print(placeID_dict[id_list[65]]['featureTypes']) #problem!\n",
    "\n",
    "# for i in range(len(featureTypes)):\n",
    "#     print(i, featureTypes[i], descriptions[i])\n",
    "\n",
    "\n",
    "\n",
    "# Several entries in the placeID_dict appear to be missing, e.g. Eteonus (383235UEte), although the entry exists in Topos Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_df['featureTypes'] = featureTypes\n",
    "place_df['description'] = descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export pandas dataframe to csv file\n",
    "place_df.to_csv(r'topos_places.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_duplicates_df = place_df.drop_duplicates(subset=['name'])\n",
    "no_duplicates_df.to_csv(r'no_duplicates_topos_places.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat topos_places.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_book = max([int(x) for x in place_df['book'].tolist()])\n",
    "# print(last_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(last_book):\n",
    "    book = i + 1\n",
    "#     print(book)\n",
    "    df_name = \"book_\" + str(book) + '.csv'\n",
    "    single_book_df = place_df[place_df.book == str(book)]\n",
    "    single_book_df.to_csv(df_name)\n",
    "    no_duplicates_book_df = single_book_df.drop_duplicates(subset=['name'])\n",
    "    no_duplicates_book_df.to_csv('no_duplicates' + df_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
